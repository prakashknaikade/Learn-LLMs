{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b863e355",
   "metadata": {
    "id": "b863e355",
    "papermill": {
     "duration": 0.01084,
     "end_time": "2023-11-07T23:38:48.872411",
     "exception": false,
     "start_time": "2023-11-07T23:38:48.861571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# USING HUGGING FACES, LANGCHAIN, AND VECTOR DATABASES TO USE OUR OWN DOCUMENTS AS KNOWLEDGE DATABASE\n",
    "\n",
    "In this notebook, we will use LangChain so that we can make queries to the language model that take into account our external information on which LLM model is not trained.\n",
    "\n",
    "The information could be our own documents, or whatever was contained in a business knowledge database.\n",
    "\n",
    "We can use different Kaggle Datasets and Language Models, so that it is easy to carry out different tests with different Datasets and Language Models (dolly-v2-3b or flan-t5-large).\n",
    "\n",
    "The data has been loaded from a Pandas DataFrame, using the **DataFrameLoader** function from the **document_loaders** library of **LangChain**.\n",
    "\n",
    "Keys:\n",
    "* RAG\n",
    "* Kaggle\n",
    "* HuggingFace\n",
    "* LangChain\n",
    "* Embeddings\n",
    "* LCEL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac2f0d",
   "metadata": {
    "id": "5bac2f0d",
    "papermill": {
     "duration": 0.010703,
     "end_time": "2023-11-07T23:38:48.894198",
     "exception": false,
     "start_time": "2023-11-07T23:38:48.883495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install and load the libraries.\n",
    "To start we need to install the necesary Python packages.\n",
    "* **[langchain](https://python.langchain.com/docs/get_started/introduction.html)**. The revolutionary framework to build apps using large language models.\n",
    "* **[sentence_transformers](https://www.sbert.net/)**. necesary to create the embeddings we are going to store in the vector database.  \n",
    "* **[chromadb](https://www.trychroma.com/)**. This is our vector Database. ChromaDB is easy to use and open source, maybe the most used Vector Database used to store embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ecaf9c5",
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T15:30:13.879044Z",
     "iopub.status.busy": "2024-12-26T15:30:13.878602Z",
     "iopub.status.idle": "2024-12-26T15:31:13.746688Z",
     "shell.execute_reply": "2024-12-26T15:31:13.745627Z",
     "shell.execute_reply.started": "2024-12-26T15:30:13.879009Z"
    },
    "id": "1ecaf9c5",
    "outputId": "502a6e6e-4523-4d89-9e73-46c37693417c",
    "papermill": {
     "duration": 81.563917,
     "end_time": "2023-11-07T23:40:10.469187",
     "exception": false,
     "start_time": "2023-11-07T23:38:48.90527",
     "status": "completed"
    },
    "scrolled": true,
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.29.2 which is incompatible.\n",
      "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
      "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\n",
      "google-cloud-bigtable 2.26.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\n",
      "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\n",
      "pandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.29.2 which is incompatible.\n",
      "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
      "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.29.2 which is incompatible.\n",
      "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
      "distributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.12.1 which is incompatible.\n",
      "pandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q chromadb==0.4.22\n",
    "!pip install -q langchain==0.1.4\n",
    "!pip install -q sentence_transformers==2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407d757",
   "metadata": {
    "id": "f407d757",
    "papermill": {
     "duration": 0.022555,
     "end_time": "2023-11-07T23:40:10.609309",
     "exception": false,
     "start_time": "2023-11-07T23:40:10.586754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the Dataset\n",
    "\n",
    "As we are working with limited computing resources in Kaggle, we limit the number of news to use with the variable MAX_NEWS.\n",
    "\n",
    "The name of the field containing the text of the news is stored in the variable *DOCUMENT* and the metadata in *TOPIC*.\n",
    "\n",
    "We are using kotartemiy/topic-labeled-news-dataset, but we can use following datasets:\n",
    "\n",
    "https://www.kaggle.com/datasets/kotartemiy/topic-labeled-news-dataset\n",
    "\n",
    "https://www.kaggle.com/datasets/gpreda/bbc-news\n",
    "\n",
    "https://www.kaggle.com/datasets/deepanshudalal09/mit-ai-news-published-till-2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ea9d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:40:04.543510Z",
     "iopub.status.busy": "2024-12-26T16:40:04.543136Z",
     "iopub.status.idle": "2024-12-26T16:40:04.969137Z",
     "shell.execute_reply": "2024-12-26T16:40:04.968042Z",
     "shell.execute_reply.started": "2024-12-26T16:40:04.543481Z"
    },
    "id": "09ea9d7c",
    "papermill": {
     "duration": 0.030688,
     "end_time": "2023-11-07T23:40:10.565135",
     "exception": false,
     "start_time": "2023-11-07T23:40:10.534447",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34403557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:40:42.624623Z",
     "iopub.status.busy": "2024-12-26T16:40:42.624002Z",
     "iopub.status.idle": "2024-12-26T16:40:43.784563Z",
     "shell.execute_reply": "2024-12-26T16:40:43.783506Z",
     "shell.execute_reply.started": "2024-12-26T16:40:42.624518Z"
    },
    "id": "34403557",
    "papermill": {
     "duration": 1.007443,
     "end_time": "2023-11-07T23:40:11.637872",
     "exception": false,
     "start_time": "2023-11-07T23:40:10.630429",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "news = pd.read_csv('/kaggle/input/topic-labeled-news-dataset/labelled_newscatcher_dataset.csv', sep=';')\n",
    "MAX_NEWS = 1000\n",
    "DOCUMENT=\"title\"\n",
    "TOPIC=\"topic\"\n",
    "\n",
    "#Because it is just a course we select a small portion of News.\n",
    "subset_news = news.head(MAX_NEWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b2f5bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T16:42:17.609675Z",
     "iopub.status.busy": "2024-12-26T16:42:17.609327Z",
     "iopub.status.idle": "2024-12-26T16:42:17.621041Z",
     "shell.execute_reply": "2024-12-26T16:42:17.619825Z",
     "shell.execute_reply.started": "2024-12-26T16:42:17.609646Z"
    },
    "id": "87b2f5bd",
    "outputId": "86a30252-add3-4455-9d81-23b1ecae7598",
    "papermill": {
     "duration": 0.046286,
     "end_time": "2023-11-07T23:40:11.705855",
     "exception": false,
     "start_time": "2023-11-07T23:40:11.659569",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>published_date</th>\n",
       "      <th>title</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.eurekalert.org/pub_releases/2020-0...</td>\n",
       "      <td>eurekalert.org</td>\n",
       "      <td>2020-08-06 13:59:45</td>\n",
       "      <td>A closer look at water-splitting's solar fuel ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>https://www.pulse.ng/news/world/an-irresistibl...</td>\n",
       "      <td>pulse.ng</td>\n",
       "      <td>2020-08-12 15:14:19</td>\n",
       "      <td>An irresistible scent makes locusts swarm, stu...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic                                               link          domain  \\\n",
       "0  SCIENCE  https://www.eurekalert.org/pub_releases/2020-0...  eurekalert.org   \n",
       "1  SCIENCE  https://www.pulse.ng/news/world/an-irresistibl...        pulse.ng   \n",
       "\n",
       "        published_date                                              title lang  \n",
       "0  2020-08-06 13:59:45  A closer look at water-splitting's solar fuel ...   en  \n",
       "1  2020-08-12 15:14:19  An irresistible scent makes locusts swarm, stu...   en  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_news.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef4e81",
   "metadata": {
    "id": "25ef4e81",
    "papermill": {
     "duration": 0.021487,
     "end_time": "2023-11-07T23:40:11.748796",
     "exception": false,
     "start_time": "2023-11-07T23:40:11.727309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CREATE THE DOCUMENT FROM THE DATAFRAME\n",
    "We are going to load the data from a pandas DataFrame. However, LangChain, through the **document_loader** library, supports multiple data sources, such as Word documents, Excel files, plain text, SQL, and more.\n",
    "\n",
    "We also imported the Chroma library, which is used to save the embeddings in the ChromaDB database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6f1238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:44:59.502033Z",
     "iopub.status.busy": "2024-12-26T16:44:59.501635Z",
     "iopub.status.idle": "2024-12-26T16:45:00.468743Z",
     "shell.execute_reply": "2024-12-26T16:45:00.467678Z",
     "shell.execute_reply.started": "2024-12-26T16:44:59.501993Z"
    },
    "id": "4c6f1238",
    "papermill": {
     "duration": 0.585876,
     "end_time": "2023-11-07T23:40:12.35627",
     "exception": false,
     "start_time": "2023-11-07T23:40:11.770394",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb88b124",
   "metadata": {
    "id": "eb88b124",
    "papermill": {
     "duration": 0.021508,
     "end_time": "2023-11-07T23:40:12.399239",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.377731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, we create the loader, indicating the data source and the name of the column in the DataFrame where we store what we could consider as the document, that is, the information we want to pass to the model so that it takes it into account in its responses.\n",
    "\n",
    "The name of the field containing the text of the news is stored in the variable *DOCUMENT* and the metadata in *TOPIC*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78614daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:50:07.469446Z",
     "iopub.status.busy": "2024-12-26T16:50:07.468848Z",
     "iopub.status.idle": "2024-12-26T16:50:07.474895Z",
     "shell.execute_reply": "2024-12-26T16:50:07.473430Z",
     "shell.execute_reply.started": "2024-12-26T16:50:07.469417Z"
    },
    "id": "78614daa",
    "papermill": {
     "duration": 0.030632,
     "end_time": "2023-11-07T23:40:12.451276",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.420644",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_loader = DataFrameLoader(subset_news, page_content_column=DOCUMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777e3ec",
   "metadata": {
    "id": "e777e3ec",
    "papermill": {
     "duration": 0.02084,
     "end_time": "2023-11-07T23:40:12.4936",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.47276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then, we use the loader to load the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0b81fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:51:31.947387Z",
     "iopub.status.busy": "2024-12-26T16:51:31.947057Z",
     "iopub.status.idle": "2024-12-26T16:51:32.056957Z",
     "shell.execute_reply": "2024-12-26T16:51:32.055645Z",
     "shell.execute_reply.started": "2024-12-26T16:51:31.947365Z"
    },
    "id": "1d0b81fd",
    "papermill": {
     "duration": 0.140406,
     "end_time": "2023-11-07T23:40:12.65498",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.514574",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_document = df_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "948950f7",
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T16:51:39.519668Z",
     "iopub.status.busy": "2024-12-26T16:51:39.519300Z",
     "iopub.status.idle": "2024-12-26T16:51:39.525639Z",
     "shell.execute_reply": "2024-12-26T16:51:39.524785Z",
     "shell.execute_reply.started": "2024-12-26T16:51:39.519610Z"
    },
    "id": "948950f7",
    "outputId": "9b1ccdff-c919-4cc7-a9f3-205f2228d494",
    "papermill": {
     "duration": 0.10378,
     "end_time": "2023-11-07T23:40:12.780315",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.676535",
     "status": "completed"
    },
    "scrolled": true,
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"A closer look at water-splitting's solar fuel potential\", metadata={'topic': 'SCIENCE', 'link': 'https://www.eurekalert.org/pub_releases/2020-08/dbnl-acl080620.php', 'domain': 'eurekalert.org', 'published_date': '2020-08-06 13:59:45', 'lang': 'en'}),\n",
       " Document(page_content='An irresistible scent makes locusts swarm, study finds', metadata={'topic': 'SCIENCE', 'link': 'https://www.pulse.ng/news/world/an-irresistible-scent-makes-locusts-swarm-study-finds/jy784jw', 'domain': 'pulse.ng', 'published_date': '2020-08-12 15:14:19', 'lang': 'en'})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_document[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82937c96",
   "metadata": {
    "id": "82937c96",
    "papermill": {
     "duration": 0.026601,
     "end_time": "2023-11-07T23:40:12.833936",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.807335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating the embeddings\n",
    "First, we import a couple of libraries.\n",
    "* CharacterTextSplitter: we will use it to group the information contained in different blocks.\n",
    "* HuggingFaceEmbeddings: it will create the embeddings in the format that we will store in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6963280e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:55:41.788908Z",
     "iopub.status.busy": "2024-12-26T16:55:41.788513Z",
     "iopub.status.idle": "2024-12-26T16:55:41.797206Z",
     "shell.execute_reply": "2024-12-26T16:55:41.795986Z",
     "shell.execute_reply.started": "2024-12-26T16:55:41.788880Z"
    },
    "id": "6963280e",
    "papermill": {
     "duration": 0.034128,
     "end_time": "2023-11-07T23:40:12.895046",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.860918",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "#from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102d83f",
   "metadata": {
    "id": "b102d83f",
    "papermill": {
     "duration": 0.026522,
     "end_time": "2023-11-07T23:40:12.948396",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.921874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We split the data into manageable chunks to store as vectors using **CharacterTextSplitter**. \n",
    "\n",
    "There isn't an exact way to do this, more chunks means more detailed context, but will increase the size of our vectorstore.  \n",
    "There are no magic numbers to do this, but it is important to consider that the larger the chunk size, the more context the model will have, but the size of our vector store will also increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "316f5b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T16:58:48.271154Z",
     "iopub.status.busy": "2024-12-26T16:58:48.270752Z",
     "iopub.status.idle": "2024-12-26T16:58:48.301675Z",
     "shell.execute_reply": "2024-12-26T16:58:48.300606Z",
     "shell.execute_reply.started": "2024-12-26T16:58:48.271126Z"
    },
    "id": "316f5b14",
    "papermill": {
     "duration": 0.07506,
     "end_time": "2023-11-07T23:40:13.050342",
     "exception": false,
     "start_time": "2023-11-07T23:40:12.975282",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=250, chunk_overlap=10)\n",
    "texts = text_splitter.split_documents(df_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c982e5e",
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T16:59:22.833228Z",
     "iopub.status.busy": "2024-12-26T16:59:22.832880Z",
     "iopub.status.idle": "2024-12-26T16:59:22.840187Z",
     "shell.execute_reply": "2024-12-26T16:59:22.838805Z",
     "shell.execute_reply.started": "2024-12-26T16:59:22.833204Z"
    },
    "id": "7c982e5e",
    "outputId": "ac42cf20-65ee-4e9d-ab70-0b855f6f8781",
    "papermill": {
     "duration": 0.103411,
     "end_time": "2023-11-07T23:40:13.18066",
     "exception": false,
     "start_time": "2023-11-07T23:40:13.077249",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"A closer look at water-splitting's solar fuel potential\", metadata={'topic': 'SCIENCE', 'link': 'https://www.eurekalert.org/pub_releases/2020-08/dbnl-acl080620.php', 'domain': 'eurekalert.org', 'published_date': '2020-08-06 13:59:45', 'lang': 'en'}),\n",
       " Document(page_content='An irresistible scent makes locusts swarm, study finds', metadata={'topic': 'SCIENCE', 'link': 'https://www.pulse.ng/news/world/an-irresistible-scent-makes-locusts-swarm-study-finds/jy784jw', 'domain': 'pulse.ng', 'published_date': '2020-08-12 15:14:19', 'lang': 'en'})]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(texts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e3387",
   "metadata": {
    "id": "779e3387",
    "papermill": {
     "duration": 0.03243,
     "end_time": "2023-11-07T23:40:13.245472",
     "exception": false,
     "start_time": "2023-11-07T23:40:13.213042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We load the library to create the pre trained model from HuggingFace to create the embeddings from sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fa973ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T16:59:48.058413Z",
     "iopub.status.busy": "2024-12-26T16:59:48.058033Z",
     "iopub.status.idle": "2024-12-26T16:59:59.613136Z",
     "shell.execute_reply": "2024-12-26T16:59:59.611969Z",
     "shell.execute_reply.started": "2024-12-26T16:59:48.058378Z"
    },
    "id": "7fa973ac",
    "outputId": "0898af45-3e70-47cb-cd07-859afbe1d043",
    "papermill": {
     "duration": 18.721786,
     "end_time": "2023-11-07T23:40:31.999291",
     "exception": false,
     "start_time": "2023-11-07T23:40:13.277505",
     "status": "completed"
    },
    "scrolled": true,
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49d2204a0cc41dd894317c1a8e39cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce2e315ff4a415385c9664f2839c8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f9d10218dc465e9b3fc5f1112992f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c2a698c2354a3b9080dfe6b397eada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259b3463fdbb4a17a2114295a62ed426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d04045873244f77b12d5fa194a5a6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b27d92d9a349ec9304e84cfebaf279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307bc3672fd241b6a5acdd5bb88b3c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df000386110d4911a35f3b5dbf6ca73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1265c4c4761455fbb38b1061fc86578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3626f1003bd8495db1747977dd8f9127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58c45e",
   "metadata": {
    "id": "ea58c45e",
    "papermill": {
     "duration": 0.034795,
     "end_time": "2023-11-07T23:40:32.069162",
     "exception": false,
     "start_time": "2023-11-07T23:40:32.034367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating the Index With Chroma\n",
    "Here we are creating the index of embeddings. Using the document, and the embedding function created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eadc6d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T17:01:54.778578Z",
     "iopub.status.busy": "2024-12-26T17:01:54.777950Z",
     "iopub.status.idle": "2024-12-26T17:02:03.537085Z",
     "shell.execute_reply": "2024-12-26T17:02:03.535444Z",
     "shell.execute_reply.started": "2024-12-26T17:01:54.778544Z"
    },
    "id": "eadc6d53",
    "papermill": {
     "duration": 8.512528,
     "end_time": "2023-11-07T23:40:40.616895",
     "exception": false,
     "start_time": "2023-11-07T23:40:32.104367",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "directory_cdb = '/kaggle/working/chromadb'\n",
    "chroma_db = Chroma.from_documents(\n",
    "    texts, embedding_function, persist_directory=directory_cdb\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708820c5",
   "metadata": {
    "id": "708820c5",
    "papermill": {
     "duration": 0.034723,
     "end_time": "2023-11-07T23:40:40.687547",
     "exception": false,
     "start_time": "2023-11-07T23:40:40.652824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LANGCHAIN\n",
    "\n",
    "Now, we create our chain with LangChain. All we do is give it a retriever and a model to call with the result obtained from the retriever.\n",
    "\n",
    "Now we are going to import RetrievalQA and HuggingFacePipeline classes from langchain module.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae871f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T17:05:14.736887Z",
     "iopub.status.busy": "2024-12-26T17:05:14.736147Z",
     "iopub.status.idle": "2024-12-26T17:05:16.114967Z",
     "shell.execute_reply": "2024-12-26T17:05:16.113939Z",
     "shell.execute_reply.started": "2024-12-26T17:05:14.736840Z"
    },
    "id": "ae871f01",
    "papermill": {
     "duration": 1.534176,
     "end_time": "2023-11-07T23:40:42.258996",
     "exception": false,
     "start_time": "2023-11-07T23:40:40.72482",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "#from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da545337",
   "metadata": {
    "id": "da545337",
    "papermill": {
     "duration": 0.035218,
     "end_time": "2023-11-07T23:40:42.330255",
     "exception": false,
     "start_time": "2023-11-07T23:40:42.295037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we create the retriever object, the responsible to return the data contained in the ChromaDB Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8478f13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T17:05:57.272398Z",
     "iopub.status.busy": "2024-12-26T17:05:57.271915Z",
     "iopub.status.idle": "2024-12-26T17:05:57.277752Z",
     "shell.execute_reply": "2024-12-26T17:05:57.276167Z",
     "shell.execute_reply.started": "2024-12-26T17:05:57.272364Z"
    },
    "id": "a8478f13",
    "papermill": {
     "duration": 0.04437,
     "end_time": "2023-11-07T23:40:42.410217",
     "exception": false,
     "start_time": "2023-11-07T23:40:42.365847",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retriever = chroma_db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadae843",
   "metadata": {
    "id": "eadae843",
    "papermill": {
     "duration": 0.03539,
     "end_time": "2023-11-07T23:40:42.481519",
     "exception": false,
     "start_time": "2023-11-07T23:40:42.446129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can use two models from Fugging Face:\n",
    "\n",
    "The first one is [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b), the smallest Dolly model. It have 3billion paramaters, more than enough for our sample, and works much better than GPT2. It's a text generation model, and therefore generates slightly more imaginative responses.\n",
    "\n",
    "The second one is a t5 model. This is a text2text-generation. so it will produce more concise and succinct responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94fe7021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T17:12:47.362206Z",
     "iopub.status.busy": "2024-12-26T17:12:47.361854Z",
     "iopub.status.idle": "2024-12-26T17:12:47.366947Z",
     "shell.execute_reply": "2024-12-26T17:12:47.365910Z",
     "shell.execute_reply.started": "2024-12-26T17:12:47.362180Z"
    },
    "id": "94fe7021",
    "papermill": {
     "duration": 0.044891,
     "end_time": "2023-11-07T23:40:42.561978",
     "exception": false,
     "start_time": "2023-11-07T23:40:42.517087",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_id = \"databricks/dolly-v2-3b\" #textgeneration model for testing\n",
    "task=\"text-generation\"\n",
    "\n",
    "#model_id = \"google/flan-t5-large\" #Nice text2text model\n",
    "#task=\"text2text-generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bef59f8",
   "metadata": {
    "id": "4bef59f8",
    "papermill": {
     "duration": 0.03455,
     "end_time": "2023-11-07T23:40:42.631714",
     "exception": false,
     "start_time": "2023-11-07T23:40:42.597164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We use HuggingFacePipeline class to create a pipeline for a specific Hugging Face language model. Let's break down the code:\n",
    "\n",
    "* **model_id**: This is the ID of the Hugging Face language model you want to use. It typically consists of the model name and version.\n",
    "* **task**: This parameter specifies the task that you want to perform using the language model. It could be \"text-generation\", \"text2text-generation\", \"question-answering\", or other tasks supported by the model.\n",
    "* **model_kwargs**: Allows you to provide additional arguments specific to the chosen model. In this case, it sets \"temperature\" to 0 (indicating deterministic output) and \"max_length\" to 256, which limits the maximum length of generated text to 256 tokens.\n",
    "* **pipeline_kwargs**: Allows you to provide extra information related to the pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bdfec13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T17:55:48.523403Z",
     "iopub.status.busy": "2024-12-26T17:55:48.523049Z",
     "iopub.status.idle": "2024-12-26T17:57:06.772996Z",
     "shell.execute_reply": "2024-12-26T17:57:06.771285Z",
     "shell.execute_reply.started": "2024-12-26T17:55:48.523375Z"
    },
    "id": "0bdfec13",
    "outputId": "588d7a01-f5c9-49b5-f08e-95d493437c24",
    "papermill": {
     "duration": 94.79476,
     "end_time": "2023-11-07T23:42:17.461674",
     "exception": false,
     "start_time": "2023-11-07T23:40:42.666914",
     "status": "completed"
    },
    "scrolled": true,
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08ae522337f40668c3a0d3cf709590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce38df99ec340d98e8d01ba30531772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42382d849b1f410dbd40aae260c5cea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d09028b5821479d906b99440d396d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b43b702c7d4692a853f15c35150bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/5.68G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#If you want to test the  T5 model remove the return_full_text parameter in pipeline_kwargs,\n",
    "# databricks/dolly-v2-3b model \n",
    "hf_llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id,\n",
    "    task=task,\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"repetition_penalty\":1.1,\n",
    "        \"return_full_text\":True\n",
    "    },\n",
    ")\n",
    "\n",
    "#If you want to test the  T5 model remove the return_full_text parameter in pipeline_kwargs,\n",
    "#also I recommend to add model_kwargs and change the temperature.\n",
    "#    model_kwargs={\n",
    "#        \"temperature\": 0,\n",
    "#        \"max_length\": 256\n",
    "#    },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc16f20",
   "metadata": {
    "id": "5cc16f20",
    "papermill": {
     "duration": 0.03792,
     "end_time": "2023-11-07T23:42:17.537572",
     "exception": false,
     "start_time": "2023-11-07T23:42:17.499652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We are setting up the ***document_qa***, a **RetrievalQA** object, that we are going to use to run the questions.\n",
    "\n",
    "The ***stuff*** type is the simplest type of chain that we can have. I get the documents from the retiever and use the language model to obtain responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa608d67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:05:47.543755Z",
     "iopub.status.busy": "2024-12-26T18:05:47.534474Z",
     "iopub.status.idle": "2024-12-26T18:05:47.564546Z",
     "shell.execute_reply": "2024-12-26T18:05:47.563021Z",
     "shell.execute_reply.started": "2024-12-26T18:05:47.543690Z"
    },
    "id": "aa608d67",
    "papermill": {
     "duration": 0.049131,
     "end_time": "2023-11-07T23:42:17.623996",
     "exception": false,
     "start_time": "2023-11-07T23:42:17.574865",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "document_qa = RetrievalQA.from_chain_type(\n",
    "    llm=hf_llm, retriever=retriever, chain_type='stuff'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f25c34f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:06:01.740423Z",
     "iopub.status.busy": "2024-12-26T18:06:01.740074Z",
     "iopub.status.idle": "2024-12-26T18:06:20.123442Z",
     "shell.execute_reply": "2024-12-26T18:06:20.122273Z",
     "shell.execute_reply.started": "2024-12-26T18:06:01.740399Z"
    },
    "id": "f25c34f0",
    "outputId": "91126027-bb57-4be6-ba52-b14be2278cce",
    "papermill": {
     "duration": 78.397935,
     "end_time": "2023-11-07T23:43:36.131687",
     "exception": false,
     "start_time": "2023-11-07T23:42:17.733752",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Can I buy a Toshiba laptop?',\n",
       " 'result': ' No, Toshiba officially stopped making laptops in April 2023.\\n\\n'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sample question for newscatcher dataset.\n",
    "response = document_qa.invoke(\"Can I buy a Toshiba laptop?\")\n",
    "\n",
    "#Sample question for BBC Dataset.\n",
    "#response = document_qa.run(\"Who is going to meet boris johnson?\")\n",
    "display(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0nVxkDzLSMgr",
   "metadata": {
    "id": "0nVxkDzLSMgr"
   },
   "source": [
    "### Using the new LCEL Architecture from LangChain.\n",
    "LangChain recommends using LCEL (LangChain Expression Language) over Chains, as LCEL is better and recommended approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ZtlFB5UhSMNl",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:08:05.597463Z",
     "iopub.status.busy": "2024-12-26T18:08:05.596981Z",
     "iopub.status.idle": "2024-12-26T18:08:05.604039Z",
     "shell.execute_reply": "2024-12-26T18:08:05.602822Z",
     "shell.execute_reply.started": "2024-12-26T18:08:05.597423Z"
    },
    "id": "ZtlFB5UhSMNl",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"Answer the question based on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "HwaLFCjxSpHF",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:08:24.704581Z",
     "iopub.status.busy": "2024-12-26T18:08:24.704197Z",
     "iopub.status.idle": "2024-12-26T18:08:24.712936Z",
     "shell.execute_reply": "2024-12-26T18:08:24.711627Z",
     "shell.execute_reply.started": "2024-12-26T18:08:24.704549Z"
    },
    "id": "HwaLFCjxSpHF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | hf_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1RpaUJjhSp9y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:08:27.721951Z",
     "iopub.status.busy": "2024-12-26T18:08:27.721497Z",
     "iopub.status.idle": "2024-12-26T18:09:02.686963Z",
     "shell.execute_reply": "2024-12-26T18:09:02.685806Z",
     "shell.execute_reply.started": "2024-12-26T18:08:27.721917Z"
    },
    "id": "1RpaUJjhSp9y",
    "outputId": "df051d4f-3c18-4a55-8f7e-5e3476679284",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: No, Toshiba officially ended its laptop manufacturing operations in 2023.\\n\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Can I buy a Toshiba laptop?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mwSm-uLnaY3k",
   "metadata": {
    "id": "mwSm-uLnaY3k"
   },
   "source": [
    "## Checking relevant information based on the cosine distance between sentences.\n",
    "\n",
    "Vector databases find the most relevant information to a user's question by measuring the distance between embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "hja5kK6daY3l",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:12:55.733530Z",
     "iopub.status.busy": "2024-12-26T18:12:55.733029Z",
     "iopub.status.idle": "2024-12-26T18:12:55.830749Z",
     "shell.execute_reply": "2024-12-26T18:12:55.829843Z",
     "shell.execute_reply.started": "2024-12-26T18:12:55.733494Z"
    },
    "id": "hja5kK6daY3l",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_s1 = embedding_function.embed_query(\n",
    "    \"I would like to eat more vegetables and exercise every day\")\n",
    "\n",
    "embedding_s2 = embedding_function.embed_query(\n",
    "    \"I will try to maintain a healthier lifestyle.\")\n",
    "\n",
    "embedding_s3 = embedding_function.embed_query(\n",
    "    \"I prefer to play football\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1FjwxUxTaY3m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:14:00.651699Z",
     "iopub.status.busy": "2024-12-26T18:14:00.651180Z",
     "iopub.status.idle": "2024-12-26T18:14:00.657357Z",
     "shell.execute_reply": "2024-12-26T18:14:00.656051Z",
     "shell.execute_reply.started": "2024-12-26T18:14:00.651647Z"
    },
    "id": "1FjwxUxTaY3m",
    "outputId": "10b67ab5-4cd0-4cc0-c1f9-6abc98cd1cf3",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " embedding_s1 = 384\n",
      " embedding_s2 =  384\n",
      " embedding_s3 =  384\n"
     ]
    }
   ],
   "source": [
    "# All the embeddings have the same lenght despite the sentence length.\n",
    "print(f\"\"\" embedding_s1 = {len(embedding_s1)}\n",
    " embedding_s2 =  {len(embedding_s2)}\n",
    " embedding_s3 =  {len(embedding_s3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "Pi6MkKKYaY3m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:14:42.902254Z",
     "iopub.status.busy": "2024-12-26T18:14:42.901709Z",
     "iopub.status.idle": "2024-12-26T18:14:42.910349Z",
     "shell.execute_reply": "2024-12-26T18:14:42.908914Z",
     "shell.execute_reply.started": "2024-12-26T18:14:42.902210Z"
    },
    "id": "Pi6MkKKYaY3m",
    "outputId": "cb930085-c4fd-4bd5-ab15-c829be982c49",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03452673181891441, 0.03168030083179474, -0.03841092437505722, 0.07523445039987564, -0.04117882251739502]\n",
      "[-0.009032459929585457, 0.014947176910936832, 0.06308789551258087, 0.06641356647014618, 0.03385468199849129]\n",
      "[0.01728086546063423, -0.019022805616259575, 0.011131885461509228, -0.0038361945189535618, 0.03133483976125717]\n"
     ]
    }
   ],
   "source": [
    "# 5 first positions of embedding_s1.\n",
    "print(embedding_s1[:5])\n",
    "print(embedding_s2[:5])\n",
    "print(embedding_s3[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MxoqDpLIaY3m",
   "metadata": {
    "id": "MxoqDpLIaY3m"
   },
   "source": [
    "Importing SKLEARN to measure the cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ntmp1iflaY3m",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:14:59.032009Z",
     "iopub.status.busy": "2024-12-26T18:14:59.031537Z",
     "iopub.status.idle": "2024-12-26T18:14:59.036853Z",
     "shell.execute_reply": "2024-12-26T18:14:59.035731Z",
     "shell.execute_reply.started": "2024-12-26T18:14:59.031970Z"
    },
    "id": "ntmp1iflaY3m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "zWS2m7J3aY3m",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:15:13.262042Z",
     "iopub.status.busy": "2024-12-26T18:15:13.261633Z",
     "iopub.status.idle": "2024-12-26T18:15:13.267637Z",
     "shell.execute_reply": "2024-12-26T18:15:13.266459Z",
     "shell.execute_reply.started": "2024-12-26T18:15:13.262011Z"
    },
    "id": "zWS2m7J3aY3m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_s1_2d = np.array(embedding_s1).reshape(1, -1)\n",
    "embedding_s2_2d = np.array(embedding_s2).reshape(1, -1)\n",
    "embedding_s3_2d = np.array(embedding_s3).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eEz0wqn_aY3m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:15:23.574470Z",
     "iopub.status.busy": "2024-12-26T18:15:23.574054Z",
     "iopub.status.idle": "2024-12-26T18:15:23.582243Z",
     "shell.execute_reply": "2024-12-26T18:15:23.580958Z",
     "shell.execute_reply.started": "2024-12-26T18:15:23.574434Z"
    },
    "id": "eEz0wqn_aY3m",
    "outputId": "41b3933d-0713-4a06-8706-db4b1d1be0df",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03452673  0.0316803  -0.03841092  0.07523445 -0.04117882]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_s1_2d[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VCKP78yEaY3n",
   "metadata": {
    "id": "VCKP78yEaY3n"
   },
   "source": [
    "S1 sentence is more similar to S2 sentence than to S3 sentence. That is because the first sentences are talking about a healthier way of live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "PcEhD2JGaY3n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:15:53.911433Z",
     "iopub.status.busy": "2024-12-26T18:15:53.911087Z",
     "iopub.status.idle": "2024-12-26T18:15:53.925286Z",
     "shell.execute_reply": "2024-12-26T18:15:53.924157Z",
     "shell.execute_reply.started": "2024-12-26T18:15:53.911406Z"
    },
    "id": "PcEhD2JGaY3n",
    "outputId": "bca12b77-e26a-462d-b966-47924d98a8c7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54180286]]\n",
      "[[0.16314692]]\n",
      "[[0.25131373]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(embedding_s1_2d, embedding_s2_2d))\n",
    "print(cosine_similarity(embedding_s1_2d, embedding_s3_2d))\n",
    "print(cosine_similarity(embedding_s2_2d, embedding_s3_2d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mncNTu_oe2i6",
   "metadata": {
    "id": "mncNTu_oe2i6"
   },
   "source": [
    "## Print embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "Jjculuboe1tA",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:16:04.344449Z",
     "iopub.status.busy": "2024-12-26T18:16:04.344055Z",
     "iopub.status.idle": "2024-12-26T18:16:04.436033Z",
     "shell.execute_reply": "2024-12-26T18:16:04.434883Z",
     "shell.execute_reply.started": "2024-12-26T18:16:04.344416Z"
    },
    "id": "Jjculuboe1tA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA for 2D visualization\n",
    "PCA_model = PCA(n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "HA_2tUU6hIoE",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T18:16:09.130440Z",
     "iopub.status.busy": "2024-12-26T18:16:09.130084Z",
     "iopub.status.idle": "2024-12-26T18:16:09.163383Z",
     "shell.execute_reply": "2024-12-26T18:16:09.162342Z",
     "shell.execute_reply.started": "2024-12-26T18:16:09.130412Z"
    },
    "id": "HA_2tUU6hIoE",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embeddings_sentences=[]\n",
    "embeddings_sentences.append(embedding_s1)\n",
    "embeddings_sentences.append(embedding_s2)\n",
    "embeddings_sentences.append(embedding_s3)\n",
    "PCA_model.fit(embeddings_sentences)\n",
    "embeddings_coord = PCA_model.transform(embeddings_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "rzKn5vd3iqQa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:16:21.762043Z",
     "iopub.status.busy": "2024-12-26T18:16:21.761527Z",
     "iopub.status.idle": "2024-12-26T18:16:21.767899Z",
     "shell.execute_reply": "2024-12-26T18:16:21.766855Z",
     "shell.execute_reply.started": "2024-12-26T18:16:21.762001Z"
    },
    "id": "rzKn5vd3iqQa",
    "outputId": "99cd1b3c-ba1c-44e1-ec83-4e39002ddbb5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.46251846 -0.44190479]\n",
      " [-0.31148548  0.50339059]\n",
      " [ 0.77400394 -0.06148581]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "L8Wbyjnyj3KU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T18:16:23.094697Z",
     "iopub.status.busy": "2024-12-26T18:16:23.094345Z",
     "iopub.status.idle": "2024-12-26T18:16:24.317706Z",
     "shell.execute_reply": "2024-12-26T18:16:24.316597Z",
     "shell.execute_reply.started": "2024-12-26T18:16:23.094668Z"
    },
    "id": "L8Wbyjnyj3KU",
    "outputId": "7c109a88-b27f-4e54-9c2c-d9bf801655ff",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x, y = zip(*embeddings_coord)\n",
    "\n",
    "# Name the points\n",
    "names = ['s1', 's2', 's3']\n",
    "# Colors\n",
    "colors = ['red', 'green', 'blue']\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    plt.scatter(x[i], y[i], marker='o', color=colors[i], label=name)\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5387b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-12T22:01:56.993351Z",
     "iopub.status.busy": "2023-07-12T22:01:56.992775Z",
     "iopub.status.idle": "2023-07-12T22:01:57.001309Z",
     "shell.execute_reply": "2023-07-12T22:01:56.999431Z",
     "shell.execute_reply.started": "2023-07-12T22:01:56.993305Z"
    },
    "id": "c5387b3e",
    "papermill": {
     "duration": 0.037288,
     "end_time": "2023-11-07T23:43:36.206248",
     "exception": false,
     "start_time": "2023-11-07T23:43:36.16896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions.\n",
    "\n",
    "We have used a vectorial database to store the information from a Kaggle dataset. We have incorporated it into a LangChain chain through a retriever, and now we are able to make queries about the information contained in the dataset to a some Hugging Face Language Models.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 836401,
     "sourceId": 1428159,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 301.368093,
   "end_time": "2023-11-07T23:43:39.05917",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-07T23:38:37.691077",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
